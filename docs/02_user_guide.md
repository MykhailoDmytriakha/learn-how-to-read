# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```python
from text_complexity_improved import calculate_text_complexity_improved

# –î–ª—è 6-–ª–µ—Ç–Ω–µ–≥–æ —Ä–µ–±–µ–Ω–∫–∞ (—Å —É—á–µ—Ç–æ–º –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞)
complexity = calculate_text_complexity_improved(
    "–ö–æ—Ç —Å–ø–∏—Ç –¥–æ–º–∞", 
    age=6, 
    include_cognitive_load=True
)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: 24 (15 –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∞—è + 9 –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è)

# –¢–æ–ª—å–∫–æ –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å (–±–µ–∑ —É—á–µ—Ç–∞ –¥–ª–∏–Ω—ã)
linguistic_only = calculate_text_complexity_improved(
    "–ö–æ—Ç —Å–ø–∏—Ç –¥–æ–º–∞",
    include_cognitive_load=False
)
# –†–µ–∑—É–ª—å—Ç–∞—Ç: 15 (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞)
```

## üìä –í–æ–∑—Ä–∞—Å—Ç–Ω—ã–µ –ø–æ—Ä–æ–≥–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏

### 6 –ª–µ—Ç (1 –∫–ª–∞—Å—Å)
- ‚úÖ **0-20**: –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è
- üëç **20-30**: –•–æ—Ä–æ—à–æ –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –ø—Ä–∞–∫—Ç–∏–∫–∏  
- ‚ö†Ô∏è **30-40**: –°–ª–æ–∂–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç –ø–æ–º–æ—â–∏ –≤–∑—Ä–æ—Å–ª–æ–≥–æ
- ‚ùå **40+**: –°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ, –æ—Ç–ª–æ–∂–∏—Ç—å –Ω–∞ –ø–æ–∑–∂–µ

### 8 –ª–µ—Ç (2-3 –∫–ª–∞—Å—Å)
- ‚úÖ **0-25**: –ò–¥–µ–∞–ª—å–Ω–æ
- üëç **25-35**: –•–æ—Ä–æ—à–æ
- ‚ö†Ô∏è **35-45**: –°–ª–æ–∂–Ω–æ
- ‚ùå **45+**: –°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ

### 10+ –ª–µ—Ç (4-5 –∫–ª–∞—Å—Å)
- ‚úÖ **0-30**: –ò–¥–µ–∞–ª—å–Ω–æ
- üëç **30-40**: –•–æ—Ä–æ—à–æ
- ‚ö†Ô∏è **40-50**: –°–ª–æ–∂–Ω–æ
- ‚ùå **50+**: –°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ

## üîß –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ

### –ü–æ–¥–±–æ—Ä —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ –≤–æ–∑—Ä–∞—Å—Ç—É:

```python
def select_texts_for_child(child_age, texts_database):
    """–ü–æ–¥–±–∏—Ä–∞–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è —Ä–µ–±–µ–Ω–∫–∞"""
    
    suitable_texts = []
    max_complexity = {6: 25, 7: 30, 8: 35, 9: 40, 10: 45, 11: 50}
    
    for text_id, text_content in texts_database.items():
        complexity = calculate_text_complexity_improved(
            text_content,
            age=child_age,
            include_cognitive_load=True
        )
        
        if complexity <= max_complexity.get(child_age, 50):
            suitable_texts.append({
                'id': text_id,
                'text': text_content,
                'complexity': complexity,
                'words': len(text_content.split())
            })
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    return sorted(suitable_texts, key=lambda x: x['complexity'])
```

### –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ:

```python
def get_next_text_difficulty(child_age, current_success_rate):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    
    base_max = {6: 25, 7: 30, 8: 35, 9: 40, 10: 45, 11: 50}
    base_complexity = base_max.get(child_age, 50)
    
    if current_success_rate >= 0.9:  # 90%+ —É—Å–ø–µ—Ö–∞
        return base_complexity + 5  # –£—Å–ª–æ–∂–Ω—è–µ–º
    elif current_success_rate >= 0.7:  # 70-89% —É—Å–ø–µ—Ö–∞
        return base_complexity  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å
    else:  # <70% —É—Å–ø–µ—Ö–∞
        return max(10, base_complexity - 10)  # –£–ø—Ä–æ—â–∞–µ–º
```

### –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–ª—è –ø–µ–¥–∞–≥–æ–≥–æ–≤:

```python
def analyze_text_for_teacher(text):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–µ–¥–∞–≥–æ–≥–∞"""
    
    from text_complexity_improved import calculate_complexity_for_age
    
    analysis = {}
    for age in [6, 7, 8, 9, 10, 11]:
        breakdown = calculate_complexity_for_age(text, age)
        analysis[age] = {
            'total': breakdown['total_complexity'],
            'linguistic': breakdown['linguistic_complexity'],
            'cognitive': breakdown['cognitive_load'],
            'recommendation': get_age_recommendation(breakdown['total_complexity'], age)
        }
    
    return analysis

def get_age_recommendation(complexity, age):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞"""
    thresholds = {
        6: [20, 30, 40], 7: [25, 35, 45], 8: [25, 35, 45],
        9: [30, 40, 50], 10: [30, 40, 50], 11: [30, 40, 50]
    }
    
    low, med, high = thresholds.get(age, [30, 40, 50])
    
    if complexity <= low:
        return "‚úÖ –ò–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç"
    elif complexity <= med:
        return "üëç –•–æ—Ä–æ—à–æ –¥–ª—è –ø—Ä–∞–∫—Ç–∏–∫–∏"
    elif complexity <= high:
        return "‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏"
    else:
        return "‚ùå –°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ"
```

## üìà –ú–∏–≥—Ä–∞—Ü–∏—è —Å —Å—Ç–∞—Ä–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:

```python
from text_complexity_improved import compare_algorithms

# –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π –∏ –Ω–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
comparison = compare_algorithms(
    "–ö–æ—Ç —Å–ø–∏—Ç –¥–æ–º–∞ —É –º–∞–º—ã",
    age=6,
    include_cognitive_load=True
)

print(f"–°—Ç–∞—Ä—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º: {comparison['old_algorithm']}")
print(f"–ù–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º: {comparison['new_algorithm']}")
print(f"–†–∞–∑–Ω–∏—Ü–∞: {comparison['difference']}")
```

### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:

```python
def update_complexity_scores(texts_database):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ—Ü–µ–Ω–∫–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    
    for text_id, text_data in texts_database.items():
        text_content = text_data['content']
        
        # –õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è)
        text_data['linguistic_complexity'] = calculate_text_complexity_improved(
            text_content, 
            include_cognitive_load=False
        )
        
        # –ü–æ–ª–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑—Ä–∞—Å—Ç–æ–≤
        text_data['age_complexity'] = {}
        for age in range(6, 12):
            text_data['age_complexity'][age] = calculate_text_complexity_improved(
                text_content,
                age=age,
                include_cognitive_load=True
            )
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ü–µ–Ω–æ–∫:

```python
def validate_algorithm_accuracy():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö"""
    
    test_cases = [
        ("–∫–æ—Ç", 6, 15, "–ü—Ä–æ—Å—Ç–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–µ—Ä–≤–æ–∫–ª–∞—Å—Å–Ω–∏–∫–∞"),
        ("–º–∞–º–∞ –º—ã–ª–∞ —Ä–∞–º—É", 6, 25, "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è —Ñ—Ä–∞–∑–∞"),
        ("—Ñ–∏–ª–æ—Å–æ—Ñ–∏—è", 10, 35, "–°–ª–æ–∂–Ω–æ–µ —Å–ª–æ–≤–æ –¥–ª—è —Å—Ç–∞—Ä—à–∏—Ö"),
    ]
    
    for text, age, expected, description in test_cases:
        actual = calculate_text_complexity_improved(
            text, age=age, include_cognitive_load=True
        )
        
        error = abs(actual - expected)
        accuracy = max(0, 100 - error * 2)  # 2% –∑–∞ –∫–∞–∂–¥—ã–π –±–∞–ª–ª –æ—à–∏–±–∫–∏
        
        print(f"{description}: {accuracy:.0f}% —Ç–æ—á–Ω–æ—Å—Ç–∏")
```

## üîç –û—Ç–ª–∞–¥–∫–∞ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

### –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:

```python
def debug_text_complexity(text, age):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Ä–∞–∑–±–∏–≤–∫—É —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
    
    from text_complexity_improved import get_complexity_breakdown
    
    breakdown = get_complexity_breakdown(text, age, include_cognitive_load=True)
    
    print(f"–¢–µ–∫—Å—Ç: '{text}' (–≤–æ–∑—Ä–∞—Å—Ç {age} –ª–µ—Ç)")
    print(f"–°–ª–æ–≤: {breakdown['words']}")
    print(f"–õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {breakdown['linguistic_complexity']:.1f}")
    print(f"  - –°–ª–æ–≥–∏: {breakdown['syllable_component']:.1f}")
    print(f"  - –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {breakdown['structural_component']:.1f}") 
    print(f"  - –õ–µ–∫—Å–∏–∫–∞: {breakdown['lexical_component']:.1f}")
    print(f"  - –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è: {breakdown['morphological_component']:.1f}")
    print(f"  - –§–æ–Ω–µ—Ç–∏–∫–∞: {breakdown['phonetic_component']:.1f}")
    print(f"–ö–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞: {breakdown['cognitive_load']:.1f}")
    print(f"–ò–¢–û–ì–û: {breakdown['total_complexity']:.1f}")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
debug_text_complexity("–ö–æ—Ç —Å–ø–∏—Ç –¥–æ–º–∞ —É –º–∞–º—ã", 6)
```

## üìö –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:

1. **–¢–æ—á–Ω—É—é –æ—Ü–µ–Ω–∫—É** –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (—É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ 50.8%)
2. **–í–æ–∑—Ä–∞—Å—Ç–Ω—É—é –∞–¥–∞–ø—Ç–∞—Ü–∏—é** –¥–ª—è –¥–µ—Ç–µ–π 6-11 –ª–µ—Ç
3. **–ì–∏–±–∫–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è** (—Å –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π –∏ –±–µ–∑)
4. **–ü—Ä–æ—Å—Ç—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é** –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–∏—Å—Ç–µ–º—ã

–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –º–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å —Å—Ç–∞—Ä–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞, –Ω–∞—á–∏–Ω–∞—è —Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä–∫–µ —Ç–µ–∫—Å—Ç–æ–≤.